{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kaggle-jigsaw-unintended-bias-in-toxicity-classification",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hoiy/kaggle-jigsaw-unintended-bias-in-toxicity-classification/blob/master/kaggle_jigsaw_unintended_bias_in_toxicity_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4dizBJYgZJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU.\n",
        "  \n",
        "\n",
        "import sys\n",
        "\n",
        "!test -d bert_repo || git clone https://github.com/google-research/bert bert_repo\n",
        "if not 'bert_repo' in sys.path:\n",
        "  sys.path += ['bert_repo']\n",
        "\n",
        "# import python modules defined by BERT\n",
        "import modeling\n",
        "import optimization\n",
        "import run_classifier\n",
        "import tokenization\n",
        "from run_classifier import *\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRjkEpMvinNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# https://cloud.google.com/resource-manager/docs/creating-managing-projects\n",
        "project_id = 'kaggle-195702'\n",
        "!gcloud config set project {project_id}\n",
        "!mkdir -p assets\n",
        "!gsutil -m rsync -rd gs://kaggle-195702-jigsaw-unintended-bias-in-toxicity-classification/assets ./assets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yiS765ega0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class JigsawUBITCProcessor(DataProcessor):\n",
        "    def get_train_examples(self, data_dir):\n",
        "        df = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
        "        train = df.sample(frac=0.8, random_state=42)\n",
        "        df = train\n",
        "        pos = df[df.target >= 0.5]\n",
        "        neg = df[df.target < 0.5].sample(n=len(pos))\n",
        "        df = pd.concat([pos, neg]).sample(frac=1)\n",
        "        return self._create_examples(df, \"train\")\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        df = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
        "        train = df.sample(frac=0.8, random_state=42)\n",
        "        df = df[~df.index.isin(train.index)]\n",
        "        pos = df[df.target >= 0.5]\n",
        "        neg = df[df.target < 0.5].sample(n=len(pos))\n",
        "        df = pd.concat([pos, neg]).sample(frac=1)\n",
        "        return self._create_examples(df, \"train\")\n",
        "\n",
        "    def get_test_examples(self, data_dir):\n",
        "        return self._create_examples(\n",
        "            pd.read_csv(os.path.join(data_dir, 'test.csv')), \"test\")\n",
        "\n",
        "    def get_labels(self):\n",
        "        return [\"0\", \"1\"]\n",
        "\n",
        "    def _create_examples(self, df, set_type):\n",
        "        examples = []\n",
        "        if set_type == 'train':\n",
        "            df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "        for i, row in tqdm(df.iterrows(), total=len(df)):\n",
        "            guid = \"%s-%s\" % (set_type, i)\n",
        "            if set_type == \"test\":\n",
        "                text_a = tokenization.convert_to_unicode(row['comment_text'])\n",
        "                label = \"0\"\n",
        "            else:\n",
        "                text_a = tokenization.convert_to_unicode(row['comment_text'])\n",
        "                label = \"1\" if row['target'] >= 0.5 else \"0\"\n",
        "            examples.append(\n",
        "              InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
        "        return examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4F6uFKJg9T5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class flags(object):\n",
        "    do_lower_case = True\n",
        "    max_seq_length = 256\n",
        "    output_dir = 'gs://kaggle-195702-jigsaw-unintended-bias-in-toxicity-classification/output'\n",
        "    dataset_dir = 'gs://kaggle-195702-jigsaw-unintended-bias-in-toxicity-classification/dataset'\n",
        "    use_tpu = True\n",
        "    tpu_name = TPU_ADDRESS\n",
        "    tpu_zone = None\n",
        "    gcp_project = None\n",
        "    init_checkpoint = 'gs://kaggle-195702-jigsaw-unintended-bias-in-toxicity-classification/assets/wwm_uncased_L-24_H-1024_A-16/bert_model.ckpt'\n",
        "    bert_config_file = 'gs://kaggle-195702-jigsaw-unintended-bias-in-toxicity-classification/assets/wwm_uncased_L-24_H-1024_A-16/bert_config.json'\n",
        "    vocab_file = 'gs://kaggle-195702-jigsaw-unintended-bias-in-toxicity-classification/assets/wwm_uncased_L-24_H-1024_A-16/vocab.txt'\n",
        "    data_dir = './assets'\n",
        "    master = None\n",
        "    save_checkpoints_steps = 3000\n",
        "    iterations_per_loop = 1000\n",
        "    num_tpu_cores = None\n",
        "    do_train = True\n",
        "    do_eval = True\n",
        "    do_pred = False\n",
        "    learning_rate = 1e-7\n",
        "    train_batch_size = 80\n",
        "    eval_batch_size = 80\n",
        "    predict_batch_size = 8\n",
        "    warmup_proportion = 0.0\n",
        "    num_train_epochs = 1.\n",
        "\n",
        "    \n",
        "FLAGS = flags()\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "tokenization.validate_case_matches_checkpoint(FLAGS.do_lower_case,\n",
        "                                              FLAGS.init_checkpoint)\n",
        "\n",
        "if not FLAGS.do_train and not FLAGS.do_eval and not FLAGS.do_predict:\n",
        "  raise ValueError(\n",
        "      \"At least one of `do_train`, `do_eval` or `do_predict' must be True.\")\n",
        "\n",
        "bert_config = modeling.BertConfig.from_json_file(FLAGS.bert_config_file)\n",
        "\n",
        "if FLAGS.max_seq_length > bert_config.max_position_embeddings:\n",
        "  raise ValueError(\n",
        "      \"Cannot use sequence length %d because the BERT model \"\n",
        "      \"was only trained up to sequence length %d\" %\n",
        "      (FLAGS.max_seq_length, bert_config.max_position_embeddings))\n",
        "\n",
        "tf.gfile.MakeDirs(FLAGS.output_dir)\n",
        "\n",
        "processor = JigsawUBITCProcessor()\n",
        "\n",
        "label_list = processor.get_labels()\n",
        "\n",
        "tokenizer = tokenization.FullTokenizer(\n",
        "    vocab_file=FLAGS.vocab_file, do_lower_case=FLAGS.do_lower_case)\n",
        "\n",
        "tpu_cluster_resolver = None\n",
        "if FLAGS.use_tpu and FLAGS.tpu_name:\n",
        "  tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(\n",
        "      FLAGS.tpu_name, zone=FLAGS.tpu_zone, project=FLAGS.gcp_project)\n",
        "\n",
        "is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
        "run_config = tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    master=FLAGS.master,\n",
        "    model_dir=FLAGS.output_dir,\n",
        "    save_summary_steps = 1000,\n",
        "    keep_checkpoint_max = 99999,\n",
        "    save_checkpoints_steps=FLAGS.save_checkpoints_steps,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=FLAGS.iterations_per_loop,\n",
        "        num_shards=FLAGS.num_tpu_cores,\n",
        "        per_host_input_for_training=is_per_host))\n",
        "\n",
        "# num_train_examples = 1443889\n",
        "# TRAIN_FILE_NAME = 'train_80.tf_record'\n",
        "\n",
        "# num_train_examples = 1804874\n",
        "# TRAIN_FILE_NAME = 'train.tf_record'\n",
        "\n",
        "num_train_examples = 3321080\n",
        "TRAIN_FILE_NAME = 'train_upsample.tf_record'\n",
        "\n",
        "\n",
        "\n",
        "train_examples = None\n",
        "num_train_steps = None\n",
        "num_warmup_steps = None\n",
        "if FLAGS.do_train:\n",
        "#   train_examples = processor.get_train_examples(FLAGS.data_dir)\n",
        "  num_train_steps = int(\n",
        "      num_train_examples / FLAGS.train_batch_size * FLAGS.num_train_epochs)\n",
        "  num_warmup_steps = int(num_train_steps * FLAGS.warmup_proportion)\n",
        "  \n",
        "train_examples, num_train_steps, num_warmup_steps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SS_NrdTHhekQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_fn = model_fn_builder(\n",
        "    bert_config=bert_config,\n",
        "    num_labels=len(label_list),\n",
        "    init_checkpoint=FLAGS.init_checkpoint,\n",
        "    learning_rate=FLAGS.learning_rate,\n",
        "    num_train_steps=num_train_steps,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    use_tpu=FLAGS.use_tpu,\n",
        "    use_one_hot_embeddings=FLAGS.use_tpu)\n",
        "\n",
        "# If TPU is not available, this will fall back to normal Estimator on CPU\n",
        "# or GPU.\n",
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=FLAGS.use_tpu,\n",
        "    model_fn=model_fn,\n",
        "    config=run_config,\n",
        "    train_batch_size=FLAGS.train_batch_size,\n",
        "    eval_batch_size=FLAGS.eval_batch_size,\n",
        "    predict_batch_size=FLAGS.predict_batch_size)\n",
        "\n",
        "if FLAGS.do_train:\n",
        "  train_file = os.path.join(FLAGS.dataset_dir, TRAIN_FILE_NAME)\n",
        "#   file_based_convert_examples_to_features(\n",
        "#       train_examples, label_list, FLAGS.max_seq_length, tokenizer, train_file)\n",
        "  tf.logging.info(\"***** Running training *****\")\n",
        "  tf.logging.info(\"  Num examples = %d\", num_train_examples)\n",
        "  tf.logging.info(\"  Batch size = %d\", FLAGS.train_batch_size)\n",
        "  tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
        "  train_input_fn = file_based_input_fn_builder(\n",
        "      input_file=train_file,\n",
        "      seq_length=FLAGS.max_seq_length,\n",
        "      is_training=True,\n",
        "      drop_remainder=True)\n",
        "  estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "\n",
        "if FLAGS.do_eval:\n",
        "  eval_examples = processor.get_dev_examples(FLAGS.data_dir)\n",
        "  num_actual_eval_examples = len(eval_examples)\n",
        "  if FLAGS.use_tpu:\n",
        "    # TPU requires a fixed batch size for all batches, therefore the number\n",
        "    # of examples must be a multiple of the batch size, or else examples\n",
        "    # will get dropped. So we pad with fake examples which are ignored\n",
        "    # later on. These do NOT count towards the metric (all tf.metrics\n",
        "    # support a per-instance weight, and these get a weight of 0.0).\n",
        "    while len(eval_examples) % FLAGS.eval_batch_size != 0:\n",
        "      eval_examples.append(PaddingInputExample())\n",
        "\n",
        "  eval_file = os.path.join(FLAGS.output_dir, \"eval.tf_record\")\n",
        "  file_based_convert_examples_to_features(\n",
        "      eval_examples, label_list, FLAGS.max_seq_length, tokenizer, eval_file)\n",
        "\n",
        "  tf.logging.info(\"***** Running evaluation *****\")\n",
        "  tf.logging.info(\"  Num examples = %d (%d actual, %d padding)\",\n",
        "                  len(eval_examples), num_actual_eval_examples,\n",
        "                  len(eval_examples) - num_actual_eval_examples)\n",
        "  tf.logging.info(\"  Batch size = %d\", FLAGS.eval_batch_size)\n",
        "\n",
        "  # This tells the estimator to run through the entire set.\n",
        "  eval_steps = None\n",
        "  # However, if running eval on the TPU, you will need to specify the\n",
        "  # number of steps.\n",
        "  if FLAGS.use_tpu:\n",
        "    assert len(eval_examples) % FLAGS.eval_batch_size == 0\n",
        "    eval_steps = int(len(eval_examples) // FLAGS.eval_batch_size)\n",
        "\n",
        "  eval_drop_remainder = True if FLAGS.use_tpu else False\n",
        "  eval_input_fn = file_based_input_fn_builder(\n",
        "      input_file=eval_file,\n",
        "      seq_length=FLAGS.max_seq_length,\n",
        "      is_training=False,\n",
        "      drop_remainder=eval_drop_remainder)\n",
        "\n",
        "  result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n",
        "\n",
        "  output_eval_file = os.path.join(FLAGS.output_dir, \"eval_results.txt\")\n",
        "  with tf.gfile.GFile(output_eval_file, \"w\") as writer:\n",
        "    tf.logging.info(\"***** Eval results *****\")\n",
        "    for key in sorted(result.keys()):\n",
        "      tf.logging.info(\"  %s = %s\", key, str(result[key]))\n",
        "      writer.write(\"%s = %s\\n\" % (key, str(result[key])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10obVTYxfVZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}